{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "casual-escape",
   "metadata": {},
   "source": [
    "---\n",
    "<div style=\"text-align: right\"> Dazed & Confusion Matrix 2.0 <br> REQUIRED TO HAVE TENSORFLOW & TENSORFLOW-PROBABILITY INSTALLED </div>\n",
    "\n",
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alternative-posting",
   "metadata": {},
   "source": [
    "# Load libriaries and functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "exceptional-plastic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theano: 1.0.4\n",
      "tensorflow: 2.3.0\n",
      "keras: 2.4.0\n",
      "tf_probability: 0.11.0\n",
      "autokeras: 1.0.12\n"
     ]
    }
   ],
   "source": [
    "# theano\n",
    "import theano\n",
    "print('theano: %s' % theano.__version__)\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "print('tensorflow: %s' % tf.__version__)\n",
    "# keras\n",
    "from tensorflow import keras\n",
    "print('keras: %s' % keras.__version__)\n",
    "import tensorflow_probability as tfp\n",
    "print('tf_probability: %s' % tfp.__version__)\n",
    "import autokeras as ak\n",
    "print('autokeras: %s' % ak.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ideal-karen",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "tfk = tf.keras\n",
    "tf.keras.backend.set_floatx(\"float64\")\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import IsolationForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "proud-script",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dietary-hanging",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entire-applicant",
   "metadata": {},
   "source": [
    "# Define helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "centered-antigua",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define helper functions.\n",
    "scaler = StandardScaler()\n",
    "detector = IsolationForest(n_estimators=1000, behaviour=\"deprecated\", contamination=\"auto\", random_state=0)\n",
    "neg_log_likelihood = lambda x, rv_x: -rv_x.log_prob(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thousand-compatibility",
   "metadata": {},
   "source": [
    "# Loading the Data\n",
    "\n",
    "As sensors tend to drift due to aging, theretically, it is better to only use data from the past month six."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "changing-italian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading the csv file from your GitHub account\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/McGill-MMA-EnterpriseAnalytics/Dazed-Confusion-Matrix/dev/data/TRAIN_911_DEMO_MERGED_ENCODED.CSV\" # Make sure the url is the raw version of the file on GitHub\n",
    "download = requests.get(url).content\n",
    "\n",
    "# Reading the downloaded content and turning it into a pandas dataframe\n",
    "\n",
    "train_data = pd.read_csv(io.StringIO(download.decode('utf-8')))\n",
    "\n",
    "# Downloading the csv file from your GitHub account\n",
    "\n",
    "url_1 = \"https://raw.githubusercontent.com/McGill-MMA-EnterpriseAnalytics/Dazed-Confusion-Matrix/dev/data/TEST_911_DEMO_MERGED_ENCODED.CSV\" # Make sure the url is the raw version of the file on GitHub\n",
    "download_1 = requests.get(url_1).content\n",
    "\n",
    "# Reading the downloaded content and turning it into a pandas dataframe\n",
    "\n",
    "test_data = pd.read_csv(io.StringIO(download_1.decode('utf-8')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "infectious-region",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['Priority_OUT_OF_SERVICE'] = test_data['Priority_OUT OF SERVICE']\n",
    "test_data = test_data.drop(['Priority_OUT OF SERVICE'], axis=1)\n",
    "train_data['Priority_OUT_OF_SERVICE'] = train_data['Priority_OUT OF SERVICE']\n",
    "train_data = train_data.drop(['Priority_OUT OF SERVICE'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "golden-terrain",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Description                 0\n",
       "Post                        0\n",
       "District                    0\n",
       "Neighborhood                0\n",
       "Longitude                   0\n",
       "Latitude                    0\n",
       "Premise                     0\n",
       "CallDescription             0\n",
       "Year                        0\n",
       "median_household_income     0\n",
       "households_below_poverty    0\n",
       "perc18_24                   0\n",
       "perc25_64                   0\n",
       "perc65up                    0\n",
       "perc_asian                  0\n",
       "perc_aa                     0\n",
       "perc_hisp                   0\n",
       "perc_white                  0\n",
       "median_price_homes_sold     0\n",
       "racial_diversity_index      0\n",
       "num_households              0\n",
       "Month                       0\n",
       "crime_hour                  0\n",
       "Outside                     0\n",
       "Weapon_FIREARM              0\n",
       "Weapon_HANDS                0\n",
       "Weapon_KNIFE                0\n",
       "Weapon_NONE                 0\n",
       "Weapon_OTHER                0\n",
       "call_hour                   0\n",
       "Season_autumn               0\n",
       "Season_spring               0\n",
       "Season_summer               0\n",
       "Season_winter               0\n",
       "Holiday                     0\n",
       "Weekend                     0\n",
       "Priority_HIGH               0\n",
       "Priority_LOW                0\n",
       "Priority_MEDIUM             0\n",
       "Priority_NON-EMERGENCY      0\n",
       "Priority_UNKNOWN            0\n",
       "Priority_OUT_OF_SERVICE     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "taken-patient",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8,  7,  3,  0,  5, 11,  4, 12,  1, 13,  2, 14,  9, 10,  6],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.Description.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "signal-disclaimer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7     1746\n",
       "8     1382\n",
       "5     1017\n",
       "3      996\n",
       "4      805\n",
       "0      517\n",
       "12     461\n",
       "2       97\n",
       "14      89\n",
       "10      57\n",
       "11      50\n",
       "6       41\n",
       "13      34\n",
       "1       31\n",
       "9       26\n",
       "Name: Description, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['Description'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "sound-memorial",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_data['Description']=test_data[\"Description\"].astype(np.float64)\n",
    "#train_data['Description']=train_data[\"Description\"].astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cloudy-battle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1838 entries, 0 to 1837\n",
      "Data columns (total 42 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Description               1838 non-null   int64  \n",
      " 1   Post                      1838 non-null   float64\n",
      " 2   District                  1838 non-null   int64  \n",
      " 3   Neighborhood              1838 non-null   int64  \n",
      " 4   Longitude                 1838 non-null   float64\n",
      " 5   Latitude                  1838 non-null   float64\n",
      " 6   Premise                   1838 non-null   int64  \n",
      " 7   CallDescription           1838 non-null   int64  \n",
      " 8   Year                      1838 non-null   int64  \n",
      " 9   median_household_income   1838 non-null   float64\n",
      " 10  households_below_poverty  1838 non-null   float64\n",
      " 11  perc18_24                 1838 non-null   float64\n",
      " 12  perc25_64                 1838 non-null   float64\n",
      " 13  perc65up                  1838 non-null   float64\n",
      " 14  perc_asian                1838 non-null   float64\n",
      " 15  perc_aa                   1838 non-null   float64\n",
      " 16  perc_hisp                 1838 non-null   float64\n",
      " 17  perc_white                1838 non-null   float64\n",
      " 18  median_price_homes_sold   1838 non-null   float64\n",
      " 19  racial_diversity_index    1838 non-null   float64\n",
      " 20  num_households            1838 non-null   float64\n",
      " 21  Month                     1838 non-null   int64  \n",
      " 22  crime_hour                1838 non-null   int64  \n",
      " 23  Outside                   1838 non-null   int64  \n",
      " 24  Weapon_FIREARM            1838 non-null   int64  \n",
      " 25  Weapon_HANDS              1838 non-null   int64  \n",
      " 26  Weapon_KNIFE              1838 non-null   int64  \n",
      " 27  Weapon_NONE               1838 non-null   int64  \n",
      " 28  Weapon_OTHER              1838 non-null   int64  \n",
      " 29  call_hour                 1838 non-null   int64  \n",
      " 30  Season_autumn             1838 non-null   int64  \n",
      " 31  Season_spring             1838 non-null   int64  \n",
      " 32  Season_summer             1838 non-null   int64  \n",
      " 33  Season_winter             1838 non-null   int64  \n",
      " 34  Holiday                   1838 non-null   int64  \n",
      " 35  Weekend                   1838 non-null   int64  \n",
      " 36  Priority_HIGH             1838 non-null   int64  \n",
      " 37  Priority_LOW              1838 non-null   int64  \n",
      " 38  Priority_MEDIUM           1838 non-null   int64  \n",
      " 39  Priority_NON-EMERGENCY    1838 non-null   int64  \n",
      " 40  Priority_UNKNOWN          1838 non-null   int64  \n",
      " 41  Priority_OUT_OF_SERVICE   1838 non-null   int64  \n",
      "dtypes: float64(15), int64(27)\n",
      "memory usage: 603.2 KB\n"
     ]
    }
   ],
   "source": [
    "test_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "varying-backing",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_data.drop(['Description'], axis=1)\n",
    "y_test = test_data[\"Description\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "devoted-defensive",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full = train_data.drop(['Description'], axis=1)\n",
    "y_train_full = train_data['Description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "large-approach",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7349, 41) (1838, 41) (7349,) (1838,) (1838, 42) (7349, 42)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_full.shape, X_test.shape, y_train_full.shape, y_test.shape, test_data.shape, train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "protecting-twins",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "indian-field",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit only to the training data\n",
    "scaler.fit(X_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "important-water",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full = scaler.transform(X_train_full)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "genuine-smith",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The validation set contains 1935 units of information from the 7350, which is 26.33% of the data \n",
    "X_valid, X_train = X_train_full[:1934], X_train_full[1934:]\n",
    "y_valid, y_train = y_train_full[:1934], y_train_full[1934:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "micro-camping",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "missing-jacob",
   "metadata": {},
   "outputs": [],
   "source": [
    "ANN_model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[41]),  \n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(20, activation=\"relu\"),\n",
    "    keras.layers.Dense(15, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "equipped-hierarchy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 41)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 30)                1260      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20)                620       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 15)                315       \n",
      "=================================================================\n",
      "Total params: 2,195\n",
      "Trainable params: 2,195\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ANN_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "portuguese-flood",
   "metadata": {},
   "outputs": [],
   "source": [
    "ANN_model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=\"sgd\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "stopped-hunter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "170/170 [==============================] - 0s 2ms/step - loss: 2.4236 - accuracy: 0.2161 - val_loss: 2.1177 - val_accuracy: 0.3154\n",
      "Epoch 2/50\n",
      "170/170 [==============================] - 0s 742us/step - loss: 1.8957 - accuracy: 0.3662 - val_loss: 1.7267 - val_accuracy: 0.4012\n",
      "Epoch 3/50\n",
      "170/170 [==============================] - 0s 807us/step - loss: 1.5738 - accuracy: 0.4720 - val_loss: 1.4653 - val_accuracy: 0.5109\n",
      "Epoch 4/50\n",
      "170/170 [==============================] - 0s 759us/step - loss: 1.3631 - accuracy: 0.5638 - val_loss: 1.2984 - val_accuracy: 0.5812\n",
      "Epoch 5/50\n",
      "170/170 [==============================] - 0s 900us/step - loss: 1.2253 - accuracy: 0.6260 - val_loss: 1.1821 - val_accuracy: 0.6339\n",
      "Epoch 6/50\n",
      "170/170 [==============================] - 0s 787us/step - loss: 1.1284 - accuracy: 0.6567 - val_loss: 1.1026 - val_accuracy: 0.6618\n",
      "Epoch 7/50\n",
      "170/170 [==============================] - 0s 813us/step - loss: 1.0609 - accuracy: 0.6770 - val_loss: 1.0501 - val_accuracy: 0.6768\n",
      "Epoch 8/50\n",
      "170/170 [==============================] - 0s 888us/step - loss: 1.0161 - accuracy: 0.6831 - val_loss: 1.0165 - val_accuracy: 0.6789\n",
      "Epoch 9/50\n",
      "170/170 [==============================] - 0s 963us/step - loss: 0.9854 - accuracy: 0.6883 - val_loss: 0.9944 - val_accuracy: 0.6830\n",
      "Epoch 10/50\n",
      "170/170 [==============================] - 0s 848us/step - loss: 0.9630 - accuracy: 0.6923 - val_loss: 0.9760 - val_accuracy: 0.6861\n",
      "Epoch 11/50\n",
      "170/170 [==============================] - 0s 841us/step - loss: 0.9452 - accuracy: 0.6949 - val_loss: 0.9655 - val_accuracy: 0.6882\n",
      "Epoch 12/50\n",
      "170/170 [==============================] - 0s 782us/step - loss: 0.9304 - accuracy: 0.6955 - val_loss: 0.9526 - val_accuracy: 0.6898\n",
      "Epoch 13/50\n",
      "170/170 [==============================] - 0s 792us/step - loss: 0.9186 - accuracy: 0.6975 - val_loss: 0.9427 - val_accuracy: 0.6872\n",
      "Epoch 14/50\n",
      "170/170 [==============================] - 0s 798us/step - loss: 0.9071 - accuracy: 0.7001 - val_loss: 0.9382 - val_accuracy: 0.6918\n",
      "Epoch 15/50\n",
      "170/170 [==============================] - 0s 812us/step - loss: 0.8989 - accuracy: 0.6964 - val_loss: 0.9297 - val_accuracy: 0.6877\n",
      "Epoch 16/50\n",
      "170/170 [==============================] - 0s 844us/step - loss: 0.8898 - accuracy: 0.6999 - val_loss: 0.9224 - val_accuracy: 0.6939\n",
      "Epoch 17/50\n",
      "170/170 [==============================] - 0s 783us/step - loss: 0.8822 - accuracy: 0.7001 - val_loss: 0.9171 - val_accuracy: 0.6898\n",
      "Epoch 18/50\n",
      "170/170 [==============================] - 0s 894us/step - loss: 0.8757 - accuracy: 0.7018 - val_loss: 0.9111 - val_accuracy: 0.6913\n",
      "Epoch 19/50\n",
      "170/170 [==============================] - 0s 812us/step - loss: 0.8690 - accuracy: 0.7014 - val_loss: 0.9079 - val_accuracy: 0.6908\n",
      "Epoch 20/50\n",
      "170/170 [==============================] - 0s 794us/step - loss: 0.8629 - accuracy: 0.7021 - val_loss: 0.9040 - val_accuracy: 0.6892\n",
      "Epoch 21/50\n",
      "170/170 [==============================] - 0s 917us/step - loss: 0.8578 - accuracy: 0.7064 - val_loss: 0.9008 - val_accuracy: 0.6944\n",
      "Epoch 22/50\n",
      "170/170 [==============================] - 0s 794us/step - loss: 0.8528 - accuracy: 0.7036 - val_loss: 0.8991 - val_accuracy: 0.6913\n",
      "Epoch 23/50\n",
      "170/170 [==============================] - 0s 788us/step - loss: 0.8480 - accuracy: 0.7073 - val_loss: 0.8922 - val_accuracy: 0.6918\n",
      "Epoch 24/50\n",
      "170/170 [==============================] - 0s 777us/step - loss: 0.8437 - accuracy: 0.7077 - val_loss: 0.8954 - val_accuracy: 0.6903\n",
      "Epoch 25/50\n",
      "170/170 [==============================] - 0s 776us/step - loss: 0.8392 - accuracy: 0.7102 - val_loss: 0.8905 - val_accuracy: 0.6898\n",
      "Epoch 26/50\n",
      "170/170 [==============================] - 0s 824us/step - loss: 0.8352 - accuracy: 0.7102 - val_loss: 0.8881 - val_accuracy: 0.6934\n",
      "Epoch 27/50\n",
      "170/170 [==============================] - 0s 812us/step - loss: 0.8314 - accuracy: 0.7112 - val_loss: 0.8854 - val_accuracy: 0.6908\n",
      "Epoch 28/50\n",
      "170/170 [==============================] - 0s 828us/step - loss: 0.8286 - accuracy: 0.7114 - val_loss: 0.8805 - val_accuracy: 0.6949\n",
      "Epoch 29/50\n",
      "170/170 [==============================] - 0s 806us/step - loss: 0.8242 - accuracy: 0.7128 - val_loss: 0.8784 - val_accuracy: 0.6949\n",
      "Epoch 30/50\n",
      "170/170 [==============================] - 0s 776us/step - loss: 0.8218 - accuracy: 0.7145 - val_loss: 0.8781 - val_accuracy: 0.6934\n",
      "Epoch 31/50\n",
      "170/170 [==============================] - 0s 724us/step - loss: 0.8177 - accuracy: 0.7152 - val_loss: 0.8813 - val_accuracy: 0.6903\n",
      "Epoch 32/50\n",
      "170/170 [==============================] - 0s 740us/step - loss: 0.8155 - accuracy: 0.7156 - val_loss: 0.8761 - val_accuracy: 0.6903\n",
      "Epoch 33/50\n",
      "170/170 [==============================] - 0s 776us/step - loss: 0.8119 - accuracy: 0.7152 - val_loss: 0.8718 - val_accuracy: 0.6939\n",
      "Epoch 34/50\n",
      "170/170 [==============================] - 0s 883us/step - loss: 0.8098 - accuracy: 0.7151 - val_loss: 0.8690 - val_accuracy: 0.6960\n",
      "Epoch 35/50\n",
      "170/170 [==============================] - 0s 869us/step - loss: 0.8064 - accuracy: 0.7156 - val_loss: 0.8741 - val_accuracy: 0.6923\n",
      "Epoch 36/50\n",
      "170/170 [==============================] - 0s 759us/step - loss: 0.8034 - accuracy: 0.7186 - val_loss: 0.8667 - val_accuracy: 0.6960\n",
      "Epoch 37/50\n",
      "170/170 [==============================] - 0s 812us/step - loss: 0.8013 - accuracy: 0.7182 - val_loss: 0.8663 - val_accuracy: 0.6960\n",
      "Epoch 38/50\n",
      "170/170 [==============================] - 0s 717us/step - loss: 0.7991 - accuracy: 0.7173 - val_loss: 0.8660 - val_accuracy: 0.6960\n",
      "Epoch 39/50\n",
      "170/170 [==============================] - 0s 730us/step - loss: 0.7961 - accuracy: 0.7182 - val_loss: 0.8646 - val_accuracy: 0.6923\n",
      "Epoch 40/50\n",
      "170/170 [==============================] - 0s 741us/step - loss: 0.7943 - accuracy: 0.7178 - val_loss: 0.8626 - val_accuracy: 0.6908\n",
      "Epoch 41/50\n",
      "170/170 [==============================] - 0s 724us/step - loss: 0.7918 - accuracy: 0.7191 - val_loss: 0.8604 - val_accuracy: 0.6918\n",
      "Epoch 42/50\n",
      "170/170 [==============================] - 0s 747us/step - loss: 0.7893 - accuracy: 0.7195 - val_loss: 0.8604 - val_accuracy: 0.6913\n",
      "Epoch 43/50\n",
      "170/170 [==============================] - 0s 721us/step - loss: 0.7867 - accuracy: 0.7213 - val_loss: 0.8650 - val_accuracy: 0.6908\n",
      "Epoch 44/50\n",
      "170/170 [==============================] - 0s 724us/step - loss: 0.7848 - accuracy: 0.7237 - val_loss: 0.8597 - val_accuracy: 0.6980\n",
      "Epoch 45/50\n",
      "170/170 [==============================] - 0s 735us/step - loss: 0.7828 - accuracy: 0.7204 - val_loss: 0.8560 - val_accuracy: 0.6980\n",
      "Epoch 46/50\n",
      "170/170 [==============================] - 0s 771us/step - loss: 0.7812 - accuracy: 0.7200 - val_loss: 0.8570 - val_accuracy: 0.6965\n",
      "Epoch 47/50\n",
      "170/170 [==============================] - 0s 1ms/step - loss: 0.7786 - accuracy: 0.7228 - val_loss: 0.8570 - val_accuracy: 0.6949\n",
      "Epoch 48/50\n",
      "170/170 [==============================] - 0s 1ms/step - loss: 0.7765 - accuracy: 0.7245 - val_loss: 0.8551 - val_accuracy: 0.6986\n",
      "Epoch 49/50\n",
      "170/170 [==============================] - 0s 912us/step - loss: 0.7753 - accuracy: 0.7234 - val_loss: 0.8542 - val_accuracy: 0.6939\n",
      "Epoch 50/50\n",
      "170/170 [==============================] - 0s 872us/step - loss: 0.7732 - accuracy: 0.7241 - val_loss: 0.8579 - val_accuracy: 0.7017\n"
     ]
    }
   ],
   "source": [
    "#Set the epich to 150 because when testing different epochs this was the point before validation loss became eratic\n",
    "ANN_history = ANN_model.fit(X_train, y_train, epochs=50,\n",
    "                    validation_data=(X_valid, y_valid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fluid-trick",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(ANN_history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "sexual-bikini",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58/58 [==============================] - 0s 606us/step - loss: 0.8419 - accuracy: 0.7100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8419079299979682, 0.7100108813928183]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ANN_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "standing-morgan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.03, 0.05, 0.88, 0.  , 0.  , 0.02, 0.  , 0.  , 0.  ,\n",
       "        0.01, 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.01, 0.  , 0.08, 0.  , 0.  , 0.83, 0.08, 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.01, 0.01, 0.01, 0.2 , 0.  , 0.  , 0.59, 0.16, 0.  , 0.  ,\n",
       "        0.01, 0.  , 0.  , 0.  ],\n",
       "       [0.06, 0.  , 0.  , 0.  , 0.  , 0.93, 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.94, 0.02, 0.  , 0.  , 0.01, 0.02, 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.01, 0.  , 0.11, 0.  , 0.  , 0.82, 0.05, 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.02, 0.06, 0.12, 0.64, 0.  , 0.  , 0.1 , 0.02, 0.  , 0.  ,\n",
       "        0.03, 0.01, 0.01, 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.04, 0.01, 0.  , 0.  , 0.3 , 0.65, 0.  , 0.  ,\n",
       "        0.  , 0.01, 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.02, 0.02, 0.13, 0.  , 0.  , 0.77, 0.05, 0.  , 0.  ,\n",
       "        0.01, 0.  , 0.  , 0.  ],\n",
       "       [0.04, 0.  , 0.01, 0.01, 0.  , 0.93, 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  ]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = X_test[:10]\n",
    "y_proba = ANN_model.predict(X_new)\n",
    "y_proba.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "typical-ranch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 7, 7, 5, 3, 7, 4, 8, 7, 5], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#y_pred = model.predict_classes(X_new) # deprecated\n",
    "y_pred = np.argmax(ANN_model.predict(X_new), axis=-1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "personalized-victor",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4\n",
       "1    7\n",
       "2    7\n",
       "3    5\n",
       "4    3\n",
       "5    7\n",
       "6    4\n",
       "7    7\n",
       "8    7\n",
       "9    5\n",
       "Name: Description, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_new = y_test[:10]\n",
    "y_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cutting-fluid",
   "metadata": {},
   "source": [
    "# Trying it under autokeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "destroyed-gibraltar",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "american-victoria",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 00m 09s]\n",
      "val_accuracy: 0.07902163687676388\n",
      "\n",
      "Best val_accuracy So Far: 0.07902163687676388\n",
      "Total elapsed time: 00h 00m 51s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "WARNING:tensorflow:Layer concatenate is casting an input tensor from dtype float32 to the layer's dtype of float64, which is new behavior in TensorFlow 2.  The layer has dtype float64 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float64, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float32 by default, call `tf.keras.backend.set_floatx('float32')`. To change just this layer, pass dtype='float32' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer concatenate is casting an input tensor from dtype float32 to the layer's dtype of float64, which is new behavior in TensorFlow 2.  The layer has dtype float64 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float64, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float32 by default, call `tf.keras.backend.set_floatx('float32')`. To change just this layer, pass dtype='float32' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer concatenate is casting an input tensor from dtype float32 to the layer's dtype of float64, which is new behavior in TensorFlow 2.  The layer has dtype float64 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float64, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float32 by default, call `tf.keras.backend.set_floatx('float32')`. To change just this layer, pass dtype='float32' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer concatenate is casting an input tensor from dtype float32 to the layer's dtype of float64, which is new behavior in TensorFlow 2.  The layer has dtype float64 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float64, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float32 by default, call `tf.keras.backend.set_floatx('float32')`. To change just this layer, pass dtype='float32' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "170/170 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0705\n",
      "Epoch 2/10\n",
      "170/170 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0705\n",
      "Epoch 3/10\n",
      "170/170 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0705\n",
      "Epoch 4/10\n",
      "170/170 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0705\n",
      "Epoch 5/10\n",
      "170/170 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0705\n",
      "Epoch 6/10\n",
      "170/170 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0705\n",
      "Epoch 7/10\n",
      "170/170 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0705\n",
      "Epoch 8/10\n",
      "170/170 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0705\n",
      "Epoch 9/10\n",
      "170/170 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0705\n",
      "Epoch 10/10\n",
      "170/170 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0705\n",
      "WARNING:tensorflow:Layer concatenate is casting an input tensor from dtype float32 to the layer's dtype of float64, which is new behavior in TensorFlow 2.  The layer has dtype float64 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float64, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float32 by default, call `tf.keras.backend.set_floatx('float32')`. To change just this layer, pass dtype='float32' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer concatenate is casting an input tensor from dtype float32 to the layer's dtype of float64, which is new behavior in TensorFlow 2.  The layer has dtype float64 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float64, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float32 by default, call `tf.keras.backend.set_floatx('float32')`. To change just this layer, pass dtype='float32' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer concatenate is casting an input tensor from dtype float32 to the layer's dtype of float64, which is new behavior in TensorFlow 2.  The layer has dtype float64 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float64, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float32 by default, call `tf.keras.backend.set_floatx('float32')`. To change just this layer, pass dtype='float32' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer concatenate is casting an input tensor from dtype float32 to the layer's dtype of float64, which is new behavior in TensorFlow 2.  The layer has dtype float64 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float64, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float32 by default, call `tf.keras.backend.set_floatx('float32')`. To change just this layer, pass dtype='float32' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer concatenate is casting an input tensor from dtype float32 to the layer's dtype of float64, which is new behavior in TensorFlow 2.  The layer has dtype float64 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float64, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float32 by default, call `tf.keras.backend.set_floatx('float32')`. To change just this layer, pass dtype='float32' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\andre\\python\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From C:\\Users\\andre\\python\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:Layer concatenate is casting an input tensor from dtype float32 to the layer's dtype of float64, which is new behavior in TensorFlow 2.  The layer has dtype float64 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float64, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float32 by default, call `tf.keras.backend.set_floatx('float32')`. To change just this layer, pass dtype='float32' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer concatenate is casting an input tensor from dtype float32 to the layer's dtype of float64, which is new behavior in TensorFlow 2.  The layer has dtype float64 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float64, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float32 by default, call `tf.keras.backend.set_floatx('float32')`. To change just this layer, pass dtype='float32' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Assets written to: .\\structured_data_classifier\\best_model\\assets\n"
     ]
    }
   ],
   "source": [
    "# It tries 10 different models.\n",
    "clf = ak.StructuredDataClassifier(overwrite=True, max_trials=5)\n",
    "# Feed the structured data classifier with training data.\n",
    "clf.fit(X_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "pressed-revolution",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer concatenate_1 is casting an input tensor from dtype float32 to the layer's dtype of float64, which is new behavior in TensorFlow 2.  The layer has dtype float64 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float64, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float32 by default, call `tf.keras.backend.set_floatx('float32')`. To change just this layer, pass dtype='float32' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function recreate_function.<locals>.restored_function_body at 0x0000029015994310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function recreate_function.<locals>.restored_function_body at 0x0000029015975550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:7 out of the last 7 calls to <function recreate_function.<locals>.restored_function_body at 0x000002901594C670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:8 out of the last 8 calls to <function recreate_function.<locals>.restored_function_body at 0x00000290159948B0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:9 out of the last 9 calls to <function recreate_function.<locals>.restored_function_body at 0x000002901594CDC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:10 out of the last 10 calls to <function recreate_function.<locals>.restored_function_body at 0x0000029015994CA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x0000029015985A60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x00000290159944C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x00000290159698B0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x00000290159AB160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x00000290159ABAF0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x0000029015975940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x00000290159B51F0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x00000290159C44C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x0000029015969040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x00000290159B5280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x00000290159C4AF0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x00000290159B53A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x0000029015994D30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x00000290159859D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x00000290159ABD30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x00000290159B5B80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x00000290159D1160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x00000290159C48B0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x0000029015994430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x00000290159D1310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x00000290159854C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x0000029015994820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x00000290159C4040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x00000290159FB790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x00000290159B5C10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x00000290159D1790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x0000029015A091F0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x0000029015975670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x00000290159FB0D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 41)]              0         \n",
      "_________________________________________________________________\n",
      "multi_category_encoding (Mul (None, 41)                0         \n",
      "_________________________________________________________________\n",
      "normalization (Normalization (None, 41)                83        \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                1344      \n",
      "_________________________________________________________________\n",
      "re_lu (ReLU)                 (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "re_lu_1 (ReLU)               (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 15)                495       \n",
      "_________________________________________________________________\n",
      "classification_head_1 (Softm (None, 15)                0         \n",
      "=================================================================\n",
      "Total params: 2,978\n",
      "Trainable params: 2,895\n",
      "Non-trainable params: 83\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = clf.export_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "racial-federation",
   "metadata": {},
   "outputs": [],
   "source": [
    "Auto_model = keras.models.Sequential([\n",
    "    keras.layers.InputLayer(input_shape=[41]),\n",
    "    keras.layers.experimental.preprocessing.CategoryEncoding(max_tokens=41, output_mode=\"count\"),\n",
    "    keras.layers.experimental.preprocessing.Normalization(),\n",
    "    keras.layers.Dense(32, activation=\"relu\"),\n",
    "    keras.layers.Dense(32, activation=\"relu\"),\n",
    "    keras.layers.Dense(15, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "manual-cookbook",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "category_encoding (CategoryE (None, 41)                0         \n",
      "_________________________________________________________________\n",
      "normalization (Normalization (None, 41)                83        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                1344      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 15)                495       \n",
      "=================================================================\n",
      "Total params: 2,978\n",
      "Trainable params: 2,895\n",
      "Non-trainable params: 83\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Auto_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "conscious-mystery",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizers.Adam(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "stylish-recycling",
   "metadata": {},
   "outputs": [],
   "source": [
    "Auto_model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer= opt,\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "romance-smoke",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    }
   ],
   "source": [
    "#Set the epich to 150 because when testing different epochs this was the point before validation loss became eratic\n",
    "Auto_history = Auto_model.fit(X_train, y_train, epochs=50,\n",
    "                    validation_data=(X_valid, y_valid))\n",
    "exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statutory-programming",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(Auto_history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expensive-glossary",
   "metadata": {},
   "outputs": [],
   "source": [
    "Auto_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respiratory-dominant",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = X_test[:10]\n",
    "y_proba = Auto_model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intimate-forward",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred = model.predict_classes(X_new) # deprecated\n",
    "y_pred = np.argmax(Auto_model.predict(X_new), axis=-1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "divided-florence",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_new = y_test[:10]\n",
    "y_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlled-aruba",
   "metadata": {},
   "source": [
    "# Trying the original ANN with adam as the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "catholic-chess",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funky-philippines",
   "metadata": {},
   "outputs": [],
   "source": [
    "adam_model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[41]),  \n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(20, activation=\"relu\"),\n",
    "    keras.layers.Dense(15, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arranged-delay",
   "metadata": {},
   "outputs": [],
   "source": [
    "adam_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confirmed-release",
   "metadata": {},
   "outputs": [],
   "source": [
    "adam_model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer= \"adam\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demonstrated-scanner",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the epich to 150 because when testing different epochs this was the point before validation loss became eratic\n",
    "adam_history = adam_model.fit(X_train, y_train, epochs=50,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "altered-congo",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(adam_history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "starting-career",
   "metadata": {},
   "outputs": [],
   "source": [
    "adam_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parallel-marsh",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = X_test[:10]\n",
    "y_proba = adam_model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "residential-perth",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred = model.predict_classes(X_new) # deprecated\n",
    "y_pred = np.argmax(adam_model.predict(X_new), axis=-1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "considerable-jefferson",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_new = y_test[:10]\n",
    "y_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fallen-remainder",
   "metadata": {},
   "source": [
    "# Trying to improve for accuracy with custom activation fucntion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiovascular-deviation",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpine-elder",
   "metadata": {},
   "source": [
    "## Custom Activation Function\n",
    "--- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiac-breathing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def my_swish(z, beta=1.0):\n",
    "    return z * tf.math.sigmoid(beta * z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approved-creation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras.layers import Activation\n",
    "get_custom_objects().update({'my_swish': Activation(my_swish)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordered-denmark",
   "metadata": {},
   "outputs": [],
   "source": [
    "swish_model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[41]),  \n",
    "    keras.layers.Dense(30, activation=\"my_swish\"),\n",
    "    keras.layers.Dense(20, activation=\"my_swish\"),\n",
    "    keras.layers.Dense(15, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "behavioral-technician",
   "metadata": {},
   "outputs": [],
   "source": [
    "swish_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secondary-channels",
   "metadata": {},
   "outputs": [],
   "source": [
    "swish_model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=\"sgd\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uniform-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the epich to 150 because when testing different epochs this was the point before validation loss became eratic\n",
    "swish_history = swish_model.fit(X_train, y_train, epochs=50,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contemporary-produce",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(swish_history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compressed-budapest",
   "metadata": {},
   "outputs": [],
   "source": [
    "swish_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ahead-wages",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = X_test[:10]\n",
    "y_proba = swish_model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confidential-somewhere",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred = model.predict_classes(X_new) # deprecated\n",
    "y_pred = np.argmax(swish_model.predict(X_new), axis=-1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civic-beginning",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_new = y_test[:10]\n",
    "y_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noticed-candidate",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
